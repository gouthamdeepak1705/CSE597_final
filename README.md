Composed Image Retrieval using Contrastive Learning and Task-oriented CLIP-based Features

Step 1: Setting up the environment and getting the pre-requisites ready before the running of the code.

Download the FashionIQ dataset: [Link](https://drive.google.com/drive/folders/1DVb606AG1aP9QZ-VIy9qRGaSz-VnbrYq?usp=sharing)<br>
FashionIQ dataset should be in the following path ./CLIP4Cir<br>
1st Download CLIP4Cir models : [LINK](https://drive.google.com/drive/folders/1-ULTy3jocqbxPgw6cOG4FM8jgXojm8kJ?usp=sharing)<br>
1st CLIP4Cir model should be in the following path ./CLIP4Cir/model<br>
2nd Download CLIP4Cir models : [LINK](https://drive.google.com/drive/folders/1-IE_O_lSupP-k1FqMVU8NBRmBSUHs5jI?usp=sharing)<br>
2nd CLIP4Cir model should be in the following path ./CLIP4Cir/CLIP4Cir/model <br>

Step 2: Run the main.ipynb 